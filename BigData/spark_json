import org.apache.spark.sql.SparkSession

val spark = SparkSession
  .builder()
  .appName("Spark Example JSON")
  .getOrCreate()

// For implicit conversions like converting RDDs to DataFrames
import spark.implicits._

JSON
val datadf = spark.read.json("/user/cloudera/input_files/stocks.json")

CSV
val stockdf = spark.read.format("csv").option("sep",",").option("inferSchema","true").option("header","true").load("/user/cloudera/input_files/stocks.csv")

SAVING IN SPECIFIED FORMAT
stockdf.select("ticker","date","close","volume","open","high","low").write.format("parquet").save("/user/cloudera/input_files/stocks.parquet")

SAVING IN SPECIFIED FORMAT WITH PARTITIONING
stockdf.select("ticker","date","close","volume","open","high","low").write.partitionBy("ticker").format("parquet").save("/user/cloudera/input_files/stocks.parquet")

datadf.show(5)

datadf.printSchema()

stockdf.groupBy("ticker").count().show()

###filter or where can be used

stockdf.filter(($"ticker" isin ("APPL")) && ($"date" isin ("3/29/18"))).show()
stockdf.filter(($"ticker" isin ("APPL")) || ($"date" isin ("3/29/18"))).show()

### TEMPORARY VIEW ###
datadf.createOrReplaceTempView("stocks")
val sqldatadf = spark.sql("select distinct ticker from stocks limit 5").show()

### GLOBAL TEMPORARY VIEW ###
datadf.createGlobalTempView("stocks_g")
val sqldatadf = spark.sql("select * from global_temp.stocks_g where ticker = 'FB' limit 5").show()
